{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d0b3f5",
   "metadata": {},
   "source": [
    "## Imports & global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e525c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Dict, Tuple\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_scheduler\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, classification_report)\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# ─── Hyper-parameters ─────────────────────────────────────────────\n",
    "BACKBONE   = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "PROJ_DIM   = 256\n",
    "LR         = 2e-5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS     = 3\n",
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BACKBONE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e622053",
   "metadata": {},
   "source": [
    "## Filtering the Hypothetical Data\n",
    "\n",
    "Filters out empty strings, whitespace-only lines, non-string types, or rows with missing/invalid labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232b4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_real(example: Dict, text_key: str) -> bool:\n",
    "    \"\"\"True - row is usable; False - row is hypothetical/placeholder.\"\"\"\n",
    "    txt = example.get(text_key, None)\n",
    "    lbl = example.get(\"label\", None)\n",
    "    if not isinstance(txt, str) or txt.strip() == \"\":\n",
    "        return False\n",
    "    return isinstance(lbl, (int, bool))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821db89",
   "metadata": {},
   "source": [
    "## Sentence encoder\n",
    "\n",
    "Wraps the MiniLM backbone and adds a lightweight projection layer.  \n",
    "Mean-pooling over the attention-mask avoids CLS dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bafe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(BACKBONE)\n",
    "        hidden = self.backbone.config.hidden_size\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(hidden, PROJ_DIM),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out    = self.backbone(input_ids, attention_mask=attention_mask)\n",
    "        hidden = out.last_hidden_state\n",
    "        mask   = attention_mask.unsqueeze(-1)\n",
    "        emb    = (hidden * mask).sum(1) / mask.sum(1)\n",
    "        return self.proj(emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de749e63",
   "metadata": {},
   "source": [
    "## Multi-task head\n",
    "\n",
    "one shared encoder + two task-specific linear heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc2f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_topic: int, num_sent: int):\n",
    "        super().__init__()\n",
    "        self.encoder = SentenceEncoder()\n",
    "        self.heads = nn.ModuleDict({\n",
    "            \"topic\"    : nn.Linear(PROJ_DIM, num_topic),\n",
    "            \"sentiment\": nn.Linear(PROJ_DIM, num_sent)\n",
    "        })\n",
    "\n",
    "    def forward(self, input_ids, attention_mask,\n",
    "                task: Literal[\"topic\", \"sentiment\"]):\n",
    "        emb = self.encoder(input_ids, attention_mask)\n",
    "        return self.heads[task](emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ea226",
   "metadata": {},
   "source": [
    "## Tokenizer helper\n",
    "\n",
    "Creates padded token IDs and attaches labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ace6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize(batch, text_key):\n",
    "    tok = tokenizer(batch[text_key], padding=\"max_length\",\n",
    "                    truncation=True, max_length=64)\n",
    "    tok.pop(\"token_type_ids\", None)\n",
    "    tok[\"labels\"] = batch[\"label\"]\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2d829",
   "metadata": {},
   "source": [
    "## Data loading & loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778d8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders() -> Tuple[Dict[str, DataLoader],\n",
    "                               int, int, list[str], list[str]]:\n",
    "    ag   = load_dataset(\"ag_news\")\n",
    "    sst2 = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "    # 1) Remove hypothetical / malformed examples\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        ag[split]   = ag[split]  .filter(_is_real, fn_kwargs={\"text_key\": \"text\"})\n",
    "        sst2[split] = sst2[split].filter(_is_real, fn_kwargs={\"text_key\": \"sentence\"})\n",
    "\n",
    "    # 2) split the dataset\n",
    "    def split(ds):\n",
    "        tr = ds[\"train\"].train_test_split(0.2, seed=42)\n",
    "        vt = tr[\"test\"].train_test_split(0.5, seed=42)\n",
    "        return tr[\"train\"], vt[\"train\"], vt[\"test\"]\n",
    "\n",
    "    ag_tr,  ag_val,  ag_test  = split(ag)\n",
    "    sst_tr, sst_val, sst_test = split(sst2)\n",
    "\n",
    "    # 3) Tokenise\n",
    "    ag_tr   = ag_tr  .map(_tokenize, batched=True, fn_kwargs={\"text_key\": \"text\"})\n",
    "    ag_val  = ag_val .map(_tokenize, batched=True, fn_kwargs={\"text_key\": \"text\"})\n",
    "    ag_test = ag_test.map(_tokenize, batched=True, fn_kwargs={\"text_key\": \"text\"})\n",
    "    sst_tr  = sst_tr .map(_tokenize, batched=True, fn_kwargs={\"text_key\": \"sentence\"})\n",
    "    sst_val = sst_val.map(_tokenize, batched=True, fn_kwargs={\"text_key\": \"sentence\"})\n",
    "    sst_test= sst_test.map(_tokenize, batched=True, fn_kwargs={\"text_key\": \"sentence\"})\n",
    "\n",
    "    # 4) Torch format & loaders\n",
    "    for ds in [ag_tr, ag_val, ag_test, sst_tr, sst_val, sst_test]:\n",
    "        ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    def L(ds, sh=False): return DataLoader(ds, BATCH_SIZE, shuffle=sh)\n",
    "    loaders = {\n",
    "        \"train_topic\"    : L(ag_tr,  True),\n",
    "        \"val_topic\"      : L(ag_val),\n",
    "        \"test_topic\"     : L(ag_test),\n",
    "        \"train_sentiment\": L(sst_tr, True),\n",
    "        \"val_sentiment\"  : L(sst_val),\n",
    "        \"test_sentiment\" : L(sst_test),\n",
    "    }\n",
    "\n",
    "    n_topic = len(set(ag_tr[\"labels\"]))\n",
    "    n_sent  = len(set(sst_tr[\"labels\"]))\n",
    "    topic_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "    sent_names  = [\"Negative\", \"Positive\"]\n",
    "    return loaders, n_topic, n_sent, topic_names, sent_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c8ba0",
   "metadata": {},
   "source": [
    "## Metrics utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2311e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsPrinter:\n",
    "    def __init__(self): self.rows = []\n",
    "\n",
    "    def log(self, epoch, task, loss, metrics):\n",
    "        self.rows.append({\"epoch\": epoch, \"task\": task,\n",
    "                          \"loss\": loss, **metrics})\n",
    "\n",
    "    def print_epoch(self, epoch):\n",
    "        df = pd.DataFrame([r for r in self.rows if r[\"epoch\"] == epoch])\n",
    "        piv = df.pivot_table(index=\"task\",\n",
    "                             values=[\"loss\", \"acc\", \"prec\", \"rec\", \"f1\"],\n",
    "                             aggfunc=\"first\")\n",
    "        with pd.option_context(\"display.float_format\", \"{:.3f}\".format):\n",
    "            print(f\"\\n=== Training metrics (epoch {epoch+1}) ===\")\n",
    "            print(piv)\n",
    "\n",
    "def macro_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"acc\" : accuracy_score(y_true, y_pred),\n",
    "        \"prec\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"rec\" : recall_score  (y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"f1\"  : f1_score      (y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f58c0",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "Alternates between topic & sentiment batches each epoch and prints epoch-level tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4cb77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, loaders):\n",
    "    model.to(DEVICE)\n",
    "    optim = AdamW(model.parameters(), lr=LR)\n",
    "    steps = EPOCHS * sum(len(loaders[k])\n",
    "                         for k in [\"train_topic\", \"train_sentiment\"])\n",
    "    sched = get_scheduler(\"linear\", optim,\n",
    "                          num_warmup_steps=int(0.1 * steps),\n",
    "                          num_training_steps=steps)\n",
    "    mp = MetricsPrinter()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        model.train()\n",
    "        for task in [\"topic\", \"sentiment\"]:\n",
    "            loader = loaders[f\"train_{task}\"]\n",
    "            tot_loss, preds, labels = 0, [], []\n",
    "            for batch in loader:\n",
    "                batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "                optim.zero_grad()\n",
    "                logits = model(batch[\"input_ids\"],\n",
    "                               batch[\"attention_mask\"], task)\n",
    "                loss = F.cross_entropy(logits, batch[\"labels\"])\n",
    "                loss.backward(); optim.step(); sched.step()\n",
    "\n",
    "                tot_loss += loss.item()\n",
    "                preds  += logits.argmax(-1).cpu().tolist()\n",
    "                labels += batch[\"labels\"].cpu().tolist()\n",
    "\n",
    "            mp.log(epoch, task, tot_loss/len(loader),\n",
    "                    macro_metrics(labels, preds))\n",
    "        mp.print_epoch(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ad42a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "872f4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loaders, stage: Literal[\"val\", \"test\"],\n",
    "             names_topic: list[str], names_sent: list[str]):\n",
    "    model.eval()\n",
    "    print(f\"\\n── Final {stage.upper()} metrics ───────────────────────────\")\n",
    "    for task, names in [(\"topic\", names_topic),\n",
    "                        (\"sentiment\", names_sent)]:\n",
    "        loader = loaders[f\"{stage}_{task}\"]\n",
    "        preds, labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "                logits = model(batch[\"input_ids\"],\n",
    "                               batch[\"attention_mask\"], task)\n",
    "                preds  += logits.argmax(-1).cpu().tolist()\n",
    "                labels += batch[\"labels\"].cpu().tolist()\n",
    "\n",
    "        mac = macro_metrics(labels, preds)\n",
    "        print(f\"{task.capitalize()} – macro: \"\n",
    "              f\"Acc={mac['acc']:.3f}  \"\n",
    "              f\"Prec={mac['prec']:.3f}  \"\n",
    "              f\"Rec={mac['rec']:.3f}  \"\n",
    "              f\"F1={mac['f1']:.3f}\")\n",
    "        print(classification_report(labels, preds,\n",
    "                                    target_names=names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d2f2a",
   "metadata": {},
   "source": [
    "## Main Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7249b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function():\n",
    "    loaders, n_topic, n_sent, t_names, s_names = prepare_loaders()\n",
    "    model = MultiTaskModel(n_topic, n_sent)\n",
    "\n",
    "    train_func(model, loaders)\n",
    "    evaluate(model, loaders, \"val\",  t_names, s_names)\n",
    "    evaluate(model, loaders, \"test\", t_names, s_names)\n",
    "\n",
    "    # store label names on the model for later use\n",
    "    model.topic_label_names     = t_names\n",
    "    model.sentiment_label_names = s_names\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b870ab",
   "metadata": {},
   "source": [
    "## Task 1 - Encoding Input Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3fb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embeddings():\n",
    "    \"\"\"Print shapes & first few values of sample sentence embeddings.\"\"\"\n",
    "    print(\"\\n── Task 1 demo ──\")\n",
    "    enc = SentenceEncoder().to(DEVICE).eval()\n",
    "    sents = [\"Fetch is the Lifehack App You Didn’t Know You Needed\",\n",
    "             \"Fetch Hacks to Earn the Most Points on a Single Receipt\"\n",
    "            ]\n",
    "    toks = tokenizer(sents, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "    toks.pop(\"token_type_ids\", None)\n",
    "    with torch.no_grad():\n",
    "        emb = enc(**toks).cpu()\n",
    "    print(\"Embeddings:\", emb.shape)\n",
    "    for each_emb in emb:\n",
    "        print(each_emb[0: 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6500fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "── Task 1 demo ──\n",
      "Embeddings: torch.Size([2, 256])\n",
      "tensor([0.1484, 0.0408, 0.0000, 0.0000, 0.0810, 0.2515, 0.1087, 0.2924])\n",
      "tensor([0.1038, 0.0419, 0.0000, 0.0000, 0.0551, 0.0809, 0.1151, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7837c998",
   "metadata": {},
   "source": [
    "## Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "767b6941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 96000/96000 [00:04<00:00, 21215.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "\n",
      "=== Training metrics (epoch 1) ===\n",
      "            acc    f1  loss  prec   rec\n",
      "task                                   \n",
      "sentiment 0.861 0.157 0.518 0.158 0.156\n",
      "topic     0.855 0.003 1.970 0.003 0.003\n",
      "\n",
      "Epoch 2/3\n",
      "\n",
      "=== Training metrics (epoch 2) ===\n",
      "            acc    f1  loss  prec   rec\n",
      "task                                   \n",
      "sentiment 0.936 0.935 0.173 0.935 0.935\n",
      "topic     0.938 0.938 0.182 0.938 0.938\n",
      "\n",
      "Epoch 3/3\n",
      "\n",
      "=== Training metrics (epoch 3) ===\n",
      "            acc    f1  loss  prec   rec\n",
      "task                                   \n",
      "sentiment 0.954 0.953 0.130 0.953 0.953\n",
      "topic     0.953 0.953 0.137 0.953 0.953\n",
      "\n",
      "── Final VAL metrics ───────────────────────────\n",
      "Topic – macro: Acc=0.936  Prec=0.937  Rec=0.936  F1=0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World      0.911     0.964     0.937      3021\n",
      "      Sports      0.992     0.966     0.978      3027\n",
      "    Business      0.944     0.877     0.910      2987\n",
      "    Sci/Tech      0.901     0.936     0.918      2965\n",
      "\n",
      "    accuracy                          0.936     12000\n",
      "   macro avg      0.937     0.936     0.936     12000\n",
      "weighted avg      0.937     0.936     0.936     12000\n",
      "\n",
      "Sentiment – macro: Acc=0.941  Prec=0.940  Rec=0.941  F1=0.941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.930     0.943     0.937      3114\n",
      "    Positive      0.951     0.939     0.945      3621\n",
      "\n",
      "    accuracy                          0.941      6735\n",
      "   macro avg      0.940     0.941     0.941      6735\n",
      "weighted avg      0.941     0.941     0.941      6735\n",
      "\n",
      "\n",
      "── Final TEST metrics ───────────────────────────\n",
      "Topic – macro: Acc=0.933  Prec=0.933  Rec=0.932  F1=0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World      0.912     0.954     0.932      3030\n",
      "      Sports      0.988     0.967     0.977      3024\n",
      "    Business      0.928     0.883     0.905      2952\n",
      "    Sci/Tech      0.904     0.926     0.915      2994\n",
      "\n",
      "    accuracy                          0.933     12000\n",
      "   macro avg      0.933     0.932     0.932     12000\n",
      "weighted avg      0.933     0.933     0.933     12000\n",
      "\n",
      "Sentiment – macro: Acc=0.939  Prec=0.938  Rec=0.938  F1=0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative      0.932     0.928     0.930      2946\n",
      "    Positive      0.944     0.947     0.946      3789\n",
      "\n",
      "    accuracy                          0.939      6735\n",
      "   macro avg      0.938     0.938     0.938      6735\n",
      "weighted avg      0.939     0.939     0.939      6735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "final_model = main_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f605c",
   "metadata": {},
   "source": [
    "## Prediction on Custom Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63bcb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences(model, sentences):\n",
    "    model.eval()\n",
    "    toks = tokenizer(sentences, return_tensors=\"pt\",\n",
    "                     padding=True, truncation=True, max_length=64).to(DEVICE)\n",
    "    toks.pop(\"token_type_ids\", None)\n",
    "    with torch.no_grad():\n",
    "        topic_logits = model(toks[\"input_ids\"], toks[\"attention_mask\"], \"topic\")\n",
    "        sent_logits  = model(toks[\"input_ids\"], toks[\"attention_mask\"], \"sentiment\")\n",
    "\n",
    "    topic_ids = topic_logits.argmax(-1).cpu().tolist()\n",
    "    sent_ids  = sent_logits.argmax(-1).cpu().tolist()\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"sentence\" : s,\n",
    "            \"topic\"    : model.topic_label_names[t_id],\n",
    "            \"sentiment\": model.sentiment_label_names[s_id],\n",
    "        }\n",
    "        for s, t_id, s_id in zip(sentences, topic_ids, sent_ids)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef89a3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'Fetch Reports Strong Momentum for 2025',\n",
       "  'topic': 'Sci/Tech',\n",
       "  'sentiment': 'Positive'},\n",
       " {'sentence': 'The market crashed and investors are worried.',\n",
       "  'topic': 'World',\n",
       "  'sentiment': 'Negative'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentences(\n",
    "    final_model,\n",
    "    [\"Fetch Reports Strong Momentum for 2025\",\n",
    "     \"The market crashed and investors are worried.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74bd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
